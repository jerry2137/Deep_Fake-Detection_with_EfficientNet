{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\choulwu2\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import timm\n",
    "\n",
    "from albumentations import Compose, RandomBrightnessContrast, \\\n",
    "    HorizontalFlip, FancyPCA, HueSaturationValue, OneOf, ToGray, \\\n",
    "    ShiftScaleRotate, ImageCompression, PadIfNeeded, GaussNoise, DualTransform\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "random.seed(42)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsotropicResize(DualTransform):\n",
    "    def __init__(self, max_side, interpolation_down, interpolation_up):\n",
    "        super(IsotropicResize, self).__init__(False, 1)\n",
    "        self.max_side = max_side\n",
    "        self.interpolation_down = interpolation_down\n",
    "        self.interpolation_up = interpolation_up\n",
    "\n",
    "    def apply(self, img, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC, **params):\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        if max(w, h) == self.max_side:\n",
    "            return img\n",
    "        if w > h:\n",
    "            scale = self.max_side / w\n",
    "            h = h * scale\n",
    "            w = self.max_side\n",
    "        else:\n",
    "            scale = self.max_side / h\n",
    "            w = w * scale\n",
    "            h = self.max_side\n",
    "        interpolation = interpolation_up if scale > 1 else interpolation_down\n",
    "\n",
    "        img = img.astype('uint8')\n",
    "        resized = cv2.resize(img, (int(w), int(h)), interpolation=interpolation)\n",
    "        return resized\n",
    "\n",
    "    def apply_to_mask(self, img, **params):\n",
    "        return self.apply(img, interpolation_down=cv2.INTER_NEAREST, interpolation_up=cv2.INTER_NEAREST, **params)\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"max_side\", \"interpolation_down\", \"interpolation_up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader\n",
    "class DeepFakesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, labels, image_size, mode='train'):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.n_samples = len(image_paths)\n",
    "    \n",
    "    def create_train_transforms(self, size):\n",
    "        return Compose([\n",
    "            ImageCompression(quality_lower=60, quality_upper=100, p=0.2),\n",
    "            GaussNoise(p=0.3),\n",
    "            HorizontalFlip(),\n",
    "            OneOf([\n",
    "                IsotropicResize(max_side=size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC),\n",
    "                IsotropicResize(max_side=size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_LINEAR),\n",
    "                IsotropicResize(max_side=size, interpolation_down=cv2.INTER_LINEAR, interpolation_up=cv2.INTER_LINEAR),\n",
    "            ], p=1),\n",
    "            PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT),\n",
    "            OneOf([RandomBrightnessContrast(), FancyPCA(), HueSaturationValue()], p=0.4),\n",
    "            ToGray(p=0.2),\n",
    "            ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=5, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "        ]\n",
    "        )\n",
    "        \n",
    "    def create_val_transform(self, size):\n",
    "        return Compose([\n",
    "            IsotropicResize(max_side=size, interpolation_down=cv2.INTER_AREA, interpolation_up=cv2.INTER_CUBIC),\n",
    "            PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = np.asarray(cv2.imread(self.image_paths[index]))\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            transform = self.create_train_transforms(self.image_size)\n",
    "        else:\n",
    "            transform = self.create_val_transform(self.image_size)\n",
    "        \n",
    "        image = transform(image=image)['image']\n",
    "        \n",
    "        return torch.tensor(image).float(), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(txt_path):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            dataset.append(words[0])\n",
    "            labels.append(int(words[1]))\n",
    "\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The evaluate function to calculate the correct predictions, positive class and negative class\n",
    "def evaluate(preds, labels):\n",
    "    rounded_preds = preds.round()\n",
    "\n",
    "    correct = sum(pred == label for pred, label in zip(rounded_preds, labels)).item()\n",
    "    positive_class = int(sum(rounded_preds).item())\n",
    "    negative_class = (len(rounded_preds) - positive_class)\n",
    "    \n",
    "    return correct, positive_class, negative_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the path of the model and the path of the txt file\n",
    "def test(model_path, data_path):\n",
    "    dataset, labels = load_data(data_path)\n",
    "\n",
    "    # set the device to cuda if available to speed up training\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(torch.cuda.get_device_name())\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    # load the data loader\n",
    "    dataset = DeepFakesDataset(dataset, np.asarray(labels), IMAGE_SIZE)\n",
    "    dl = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    del dataset\n",
    "\n",
    "    model = timm.create_model('tf_efficientnetv2_m', pretrained=True, num_classes=1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(model_path), map_location=torch.device('cpu'))\n",
    "\n",
    "    model = model.to(device)\n",
    "    all_preds = torch.Tensor()\n",
    "    all_labels = torch.Tensor()\n",
    "\n",
    "    model.eval()\n",
    "    for images, labels in tqdm(dl, desc='Testing'):\n",
    "        images = np.transpose(images, (0, 3, 1, 2))\n",
    "        images = images.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(images)\n",
    "        \n",
    "        y_pred = y_pred.cpu()\n",
    "\n",
    "        all_preds = torch.cat((all_preds, torch.sigmoid(y_pred)))\n",
    "        all_labels = torch.cat((all_labels, labels))\n",
    "\n",
    "    corrects, positive, negative = evaluate(all_preds, all_labels)\n",
    "    accuracy = corrects / len(all_labels)\n",
    "    return accuracy, positive / len(all_labels), negative / len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 862/862 [09:21<00:00,  1.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9690039175856066, 0.5128228380731282, 0.4871771619268717)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please replace 'project_data.txt' with the path to the txt file\n",
    "accuracy, positivity, negativity = test('model_33_10', 'project_data.txt')\n",
    "accuracy, positivity, negativity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
